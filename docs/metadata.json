[
    {
        "category": "Document",
        "section": "1",
        "title": "What are Ladder and NOM?",
        "summary": "**Ladder and NOM: Simplifying Neural Network Development**\n\n### Overview\nLadder and NOM are two complementary frameworks designed to simplify neural network training and analysis, making it more accessible to both beginners and experienced researchers.\n\n### Key Features\n\n#### Ladder: A Graphical Interface for Neural Networks\n* Provides a drag-and-drop GUI for designing and visualizing neural networks.\n* Suitable for:\n\t+ Beginners: Simplifies model creation without programming expertise.\n\t+ Research Projects: Facilitates architectural experimentation.\n\t+ Data Analysis: Offers clear model structure visualization.\n\t+ Education: Enhances interactive learning of deep learning concepts.\n\n#### NOM: A Python-Based Neural Network Library\n* Built on top of TensorFlow, providing a simplified API for neural network development.\n* Key features:\n\t+ Configuration-Based Modeling: Reduces extensive coding needs.\n\t+ Seamless Ladder Integration: Converts Ladder's visual models into TensorFlow-compatible code.\n\t+ Simplified Training & Inference: Streamlines hyperparameter tuning and execution.\n\t+ Framework Independence: Can adapt to other deep learning libraries.\n\n### Workflow\n1. **Model Creation**: Users design neural networks in Ladder.\n2. **Translation**: NOM converts the graphical model into TensorFlow code.\n3. **Training & Execution**: NOM trains the model efficiently.\n4. **Visualization**: Ladder displays results for analysis.\n\nBy combining Ladder's graphical capabilities with NOM's streamlined Python API, this framework reduces the complexity of neural network development, making deep learning more accessible to a wider audience."
    },
    {
        "category": "Document",
        "section": "2",
        "title": "Start Using Ladder",
        "summary": "Here is the summary of the content in a concise and structured manner, within 250 words:\n\n**Getting Started with Ladder**\n\nLadder is a graphical user interface (GUI) for building and managing deep learning models. It simplifies the process by allowing users to design neural networks visually without extensive coding.\n\n**Step 1: Creating a Project**\n\n* Create a new project in Ladder, defining its purpose.\n* Build the model graphically using drag-and-drop tools.\n* Save the project as a .json file for later sharing or editing.\n\n**Step 2: Exporting and Running the Model**\n\n* Download the Python script based on NOM (Neural Object Model).\n* Run the script locally or upload it to cloud computing resources (e.g., Google Colab, AWS).\n\n**Step 3: Analyzing Training Results in Ladder**\n\n* Upload the results folder back into Ladder.\n* Visualize training logs, including loss curves, accuracy metrics, and trace logs.\n\n**Getting Help**\n\n* Visit our tutorial page for a step-by-step guide to building and training your first model with Ladder.\n* Use renowned image datasets and tabel data as examples to get started."
    },
    {
        "category": "Document",
        "section": "3",
        "title": "Supported Data in Ladder",
        "summary": "Here is a concise and structured summary of the section:\n\n**Supported Data in Ladder**\n\nLadder supports two primary types of datasets for training: data tables (CSV format) and image datasets.\n\n### **Data Tables (CSV Format)**\n\n* Supported formats: CSV files\n* Options for importing:\n\t+ Uploading a CSV file from your device\n\t+ Pasting data directly into Ladder using Ctrl + V\n\t+ Skipping file selection or pasting, but manually specifying \"Column Count\" and \"File Location\"\n* File size considerations: recommended to use CSV files under 1GB for optimal performance\n\n### **Image Datasets**\n\n* Preloaded datasets:\n\t+ MNIST\n\t+ CIFAR-10 (downloadable from the [Explore Data](https://cssa.cc.ncku.edu.tw/ladder/get_started/explore/) page)\n* Custom image datasets:\n\t+ Upload and configure your own image dataset for training deep learning models\n\t+ Choose between Image to Classification or Image to Image tasks\n\n### **Setting Up Training Data**\n\n* For image-based tasks, specify the Folder Location where training images are stored (supported formats: .jpg, .jpeg, .png, .gif, and .bmp)\n* For Image to Classification task, upload a CSV file containing image file names and their corresponding labels"
    },
    {
        "category": "Document",
        "section": "4",
        "title": "Configure Test Data",
        "summary": "Here is a concise and structured summary of the section:\n\n**Ladder's Test Data Configuration**\n\nLadder offers flexible options for defining test data to ensure proper validation while preventing data leakage.\n\n* **Preloaded Image Datasets**: Ladder uses predefined training and test splits for renowned image datasets like MNIST or CIFAR-10.\n* **Custom Image Datasets**: Users have full control over test data configuration:\n\t+ Specify an independent test dataset by providing a separate test image folder and label CSV file.\n\t+ Alternatively, split the original dataset into test and train sets with adjustable proportions in the Properties Panel of the data source node.\n* **Data Table Datasets**: Users can adjust the test proportion from the original dataset in the Properties Panel of the data source node.\n\nThis summary maintains a clear and structured format, using bullet points where necessary, while preserving important technical details within the 250-word limit."
    },
    {
        "category": "Document",
        "section": "5",
        "title": "Configuring Data Sources and Image Preprocessing in Ladder",
        "summary": "**Summary:**\n\n* **Configuring Data Sources in Ladder:**\n\t+ Modify CSV file location by selecting node > Properties or right-clicking > Folder Location.\n\t+ Currently, no re-pasting of data tables within a project; create new project instead.\n* **Image Preprocessing in Ladder:**\n\t+ Automatic data augmentation for CIFAR-10 (random flipping, brightness/contrast adjustment, cropping).\n\t+ Crop size adjustable in \"Input\" node properties.\n\t+ MNIST datasets do not undergo data augmentation.\n\t+ Future developments expected for manual image preprocessing options.\n\t+ Support for circular data types (e.g., color hue, angular values)."
    },
    {
        "category": "Document",
        "section": "6",
        "title": "Adding and Removing Hidden Layers",
        "summary": "Here is a concise and structured summary of the section:\n\n**Adding and Removing Hidden Layers in Ladder**\n\nLadder offers multiple intuitive ways to add and remove hidden layers in a neural network model, ensuring mathematical validity.\n\n**Adding Hidden Layers:**\n\n* Click the \"+\" button at the bottom of the model graph to add a layer at the end.\n* Right-click an existing layer or data preprocessing node and choose \"Insert After\" to place a hidden layer before its subsequent connections.\n* Select \"Create a Layer\" to append a new layer, which may create a branch if the existing layer is already connected to another one.\n* Drag a desired model layer from the left-side toolbar onto the \"+\" button at the intended location.\n\n**Removing Hidden Layers:**\n\n* Right-click the layer and select \"Delete\".\n\nNote that inserting or removing a hidden layer may be restricted due to mathematical conflicts, which can be resolved by checking shape restrictions of later layers."
    },
    {
        "category": "Document",
        "section": "7",
        "title": "Project Saving and Load Previous Edited Model",
        "summary": "**Project Saving and Load Previous Edited Model**\n\n### **Saving Projects**\n\n*   Ladder allows users to save their neural network models and training configurations for future use.\n*   Saved project files follow the NOM (Neural Object Model) JSON format, retaining all relevant model settings:\n    *   Architecture\n    *   Hyperparameters\n    *   Training configurations\n\n**Saving a Project:**\n\n1.  Click the \"Project\" button at the upper-right corner of the interface.\n2.  Press the \"Save Project\" button to save the project as an NOM-defined JSON file.\n\n### **Loading Saved Projects**\n\n*   To resume work on a saved project:\n    1.  Go to Ladder start screen\n    2.  Click \"Open a Neural Object Model\"\n    3.  Everything will be resumed\n\n**Important Notes:**\n\n*   Project files are only saved in NOM format.\n*   Saved projects can only be loaded and used within the Ladder platform."
    },
    {
        "category": "Document",
        "section": "8",
        "title": "Adjusting Train Settings and Training Models",
        "summary": "Here's a concise and structured summary of the section:\n\n**Configuring and Training Models with Ladder**\n\nLadder provides an intuitive interface for configuring various training settings and hyperparameters to fine-tune models for optimal performance.\n\n**Configurable Training Settings:**\n\n* Number of Epochs\n* Cross-Validation Type\n* Batch Size\n* Data Shuffling\n* Repeated Runs Count\n* Tracking Frequency\n* Log Frequency\n* Save Frequency\n* Test Frequency\n* Weight Frequency\n* Trace Count & Trace Frequency\n\n**Saving Projects and Train Scripts:**\n\n1. Saving the Project:\n\t* NOM format (project.json)\n\t* Python Script (train.py)\n2. Executing the Training Script:\n\t* Run Locally\n\t* Run on Cloud Computing Resources (e.g., Google Colab, AWS, Google Cloud, or Kaggle Notebooks)\n\n**Reviewing Training Results:**\n\n1. Open the results folder in Ladder to review training outcomes.\n\nBy following these steps, users can efficiently configure, train, and analyze their models using Ladder."
    },
    {
        "category": "Document",
        "section": "9",
        "title": "Train Logs and Results",
        "summary": "**Train Logs and Results**\n\n### Overview\nLadder provides tools to analyze and interpret training performance through detailed logs and visualizations.\n\n### Accessing Training Logs\nTo review results, click the \"Open a Results Folder\" button, which loads the training logs based on configuration settings applied before training. The logs provide insights into model performance, helping users diagnose issues, track progress, and refine their models accordingly.\n\n### Understanding the Train Log\n\n* **X-Axis (Global Step):** Represents total optimization steps taken during training.\n* **Y-Axis (Loss Value, Green Line):** Displays average loss at each step. A decreasing curve suggests effective learning.\n* **Y-Axis (Learning Rate, Blue Line):** Shows how the optimizer adjusts the learning rate over time.\n\n### Understanding the Trace Log\nThe trace log provides a granular view of model training by capturing results at specified intervals based on the trace frequency setting.\n\n* Displays performance metrics such as accuracy, loss, or validation results at different checkpoints.\n* Helps identify trends and anomalies during training.\n* Useful for debugging and determining the optimal stopping point for training."
    },
    {
        "category": "Document",
        "section": "10",
        "title": "Supported Layers on Ladder",
        "summary": "Here is a concise and structured summary of the section:\n\n**Ladder Supported Layers**\n\nLadder supports a wide range of layers, categorized into 11 groups. These include:\n\n* **MobileNet Family**: MobileNet V1, V2, V3 (small/large) for mobile and edge devices\n* **Basic Layers**: FCL, Conv/DeConv, Pooling (Max/Avg)\n* **Recurrent Layers**: RNN, GRU, LSTM, BiRNN, BiGRU, BiLSTM\n* **Normalization & Activation**: BN, Softmax\n* **Advanced Convolutions**: Conv1d/2d/3d, D_conv2d\n* **Pooling & Flattening**: Max/Avg Pooling, Flatten\n* **Manipulation Layers**: Reshape, Concat, Zeros/Ones\n* **Math Operations**: Add, Multiply, Divide, Pow, Sqrt, Exp, Mean, Square\n* **Dropout & Noise**: Dropout, Noise\n* **External Layers**: TF Hub (pre-trained models)\n* **Special Layers**: Collector, Task (Ladder-specific for task-based modules)\n\nThese layers are designed to simplify neural network development and provide a comprehensive set of tools for building complex models."
    },
    {
        "category": "Document",
        "section": "11",
        "title": "Special Layers",
        "summary": "Here is a concise and structured summary of the section:\n\n**Special Layers in Ladder**\n\nLadder enables users to create bypassing layers by allowing layer connection mode through hovering over a layer or right-clicking and selecting \"Attach on Layer\" or \"Connect to Layer\". This allows for modifying connections between layers.\n\n**Key Features:**\n\n* **Auto-Connections:** High-level layers support auto-connections, enabling concatenation, sum, multiplication, or blending of layers with different matrix sizes.\n* **Learning Layers:** Automatically applied when incoming matrices have varying dimensions, adjusting them to match the core incoming layer.\n* **Convolutional Layers:** Can be used on non-image data, automatically reshaping incoming data into a 4D format (Batch/Height/Width/Channel) if necessary.\n* **Collector Layer:** A special high-level layer that receives inputs from multiple layers without explicit linear transformation, offering configurations for activation functions and output reshaping.\n\n**Benefits:**\n\n* Simplifies creation of bypassing layers\n* Enables auto-connections between layers with different matrix sizes\n* Allows convolutional layers to be used on non-image data\n* Provides a Collector layer for receiving inputs from multiple layers."
    },
    {
        "category": "Document",
        "section": "12",
        "title": "Supported Activation Functions on Ladder",
        "summary": "Here is the summary of the section in a concise and structured manner:\n\n**Ladder and NOM: A Simplified Neural Network Development Framework**\n\n* **Overview**: Ladder and NOM are complementary frameworks designed to simplify neural network training and analysis.\n* **Key Features**:\n\t+ **Ladder**: A graphical user interface (GUI) for building, managing, and visualizing neural networks. Useful for beginners, research projects, data analysis, and education.\n\t+ **NOM**: A Python-based library built on top of TensorFlow that abstracts low-level details, allowing users to define models with structured configurations.\n* **How They Work Together**:\n\t1. Model creation in Ladder\n\t2. Data conversion by NOM\n\t3. Training and execution in NOM\n\t4. Results visualization in Ladder\n\nThis integration makes deep learning development more accessible, combining visual modeling with powerful Python-based execution."
    },
    {
        "category": "Document",
        "section": "13",
        "title": "Developers and Development History",
        "summary": "**Summary**\n\n### Overview of Ladder and NOM\n\nLadder and NOM are complementary frameworks developed by the Creative System and Software Applications Laboratory from National Cheng Kung University, Taiwan. They aim to simplify neural network training and analysis, making it more accessible to both beginners and experienced researchers.\n\n### Key Features of Ladder\n\n* **Graphical Interface**: A drag-and-drop GUI for designing and visualizing neural networks.\n* **Accessibility**: Easy-to-use interface for model creation without coding expertise.\n* **Scalability**: Gradual transition from visual model editing to code-level customization.\n* **Education and SME Focus**: Promotes AI knowledge dissemination, making neural network technology accessible to students and small businesses.\n\n### Key Features of NOM\n\n* **Python-Based Library**: Abstracts low-level details, allowing users to define models with structured configurations.\n* **Configuration-Based Modeling**: Reduces extensive coding needs.\n* **Seamless Ladder Integration**: Converts Ladder's visual models into TensorFlow-compatible code.\n* **Simplified Training & Inference**: Streamlines hyperparameter tuning and execution.\n\n### How They Work Together\n\n1. **Model Creation**: Users design neural networks in Ladder.\n2. **Translation**: NOM converts the graphical model into TensorFlow code.\n3. **Training & Execution**: NOM trains the model efficiently.\n4. **Visualization**: Ladder displays results for analysis.\n\nThis integration makes deep learning development more accessible, combining **visual modeling** with **powerful Python-based execution**."
    }
]